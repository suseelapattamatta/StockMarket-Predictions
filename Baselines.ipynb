{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nimmi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install nltk\n",
    "#!pip install tensorflow\n",
    "#!pip install keras\n",
    "import sklearn as sk\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import nltk\n",
    "import tensorflow\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from pandas import DataFrame\n",
    "from matplotlib import pyplot\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "#import sys/\n",
    "#!conda install --yes --prefix {sys.prefix} anaconda bcolz \n",
    "import bcolz\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_news(news):\n",
    "    _news = news.replace('b\\\"', \"\")\n",
    "    _news = _news.replace('b\\'', \"\")\n",
    "    _news = _news.lower()\n",
    "    _news = re.sub(\"[^a-zA-Z]\", \" \",_news)\n",
    "    _news = re.sub('[\\s]+', ' ', _news)\n",
    "    \n",
    "    tokens = _news.split(\" \")\n",
    "    if \"\" in tokens:\n",
    "        tokens.remove(\"\")\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer() \n",
    "    tokens = [lemmatizer.lemmatize(w) for w in tokens]\n",
    "    #remove punctuation from each token\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    tokens = [w.translate(table) for w in tokens]\n",
    "    \n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    # filter out stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "    # filter out short tokens\n",
    "    tokens = [word for word in tokens if len(word) > 1]\n",
    "    \n",
    "    _news = ' '.join(tokens)    \n",
    "     \n",
    "    return _news\n",
    "\n",
    "\n",
    "def read_data():\n",
    "\n",
    "    data = pd.read_csv(\"../Datasets/djia/Combined_News_DJIA.csv\")\n",
    "    \n",
    "    dfs = []\n",
    "    data[\"News\"] = \"\"\n",
    "    for i in range(1,25):\n",
    "        col = \"Top\"+str(i)\n",
    "        data[\"News\"] = data[\"News\"] +\" \"+ data[col]\n",
    "    data = data.dropna()\n",
    "    data['PreProcessedNews'] = data['News'].map(process_news)\n",
    "    \n",
    "    data = data[['Date', 'News', 'PreProcessedNews', 'Label']]\n",
    "    \n",
    "    stock_prices = \"../Datasets/djia/upload_DJIA_table.csv\"\n",
    "    stock_data = pd.read_csv(stock_prices)\n",
    "    \n",
    "    print(data.head(2))\n",
    "    print(stock_data.head(2))\n",
    "    \n",
    "    \n",
    "    #merged_dataframe = data.merge(stock_data, how='inner', on='Date')\n",
    "    merged_dataframe = pd.merge(data, stock_data, how='inner', on = 'Date')\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    Xy_train = merged_dataframe[:int(len(data)*0.6)]\n",
    "    Xy_valid = merged_dataframe[int(len(data)*0.6):int(len(data)*0.8)]\n",
    "    Xy_test = merged_dataframe[int(len(data)*0.8):]\n",
    "    \n",
    "    return merged_dataframe, Xy_train, Xy_valid, Xy_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date                                               News  \\\n",
      "0  2008-08-08   b\"Georgia 'downs two Russian warplanes' as co...   \n",
      "1  2008-08-11   b'Why wont America and Nato help us? If they ...   \n",
      "\n",
      "                                    PreProcessedNews  Label  \n",
      "0  georgia two russian warplane country move brin...      0  \n",
      "1  wont america nato help wont help help iraq bus...      1  \n",
      "         Date          Open          High           Low         Close  \\\n",
      "0  2016-07-01  17924.240234  18002.380859  17916.910156  17949.369141   \n",
      "1  2016-06-30  17712.759766  17930.609375  17711.800781  17929.990234   \n",
      "\n",
      "      Volume     Adj Close  \n",
      "0   82160000  17949.369141  \n",
      "1  133030000  17929.990234  \n"
     ]
    }
   ],
   "source": [
    "news, Xy_train, Xy_valid, Xy_test = read_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non data-dependent method\n",
    "Predictor which always predict up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = len(Xy_test[Xy_test['Label']==1])\n",
    "tn = 0\n",
    "fn = 0\n",
    "fp = len(Xy_test[Xy_test['Label']==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "f_measure = (2 * precision * recall) / (precision + recall)\n",
    "accuracy = (tp+tn)/(tp+tn+fp+fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.507537688442211\n",
      "1.0\n",
      "0.6733333333333333\n",
      "0.507537688442211\n"
     ]
    }
   ],
   "source": [
    "print(precision)\n",
    "print(recall)\n",
    "print(f_measure)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data-dependent method\n",
    "The predictor which always predict the previous day trend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "398"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Xy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "398"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.concatenate((Xy_valid['Label'].values[-1:], Xy_test['Label'].values[:-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.concatenate((Xy_valid['Label'].values[-1:], Xy_test['Label'].values[:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-d8bcc895ea64>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Xy_test['Prediction'] = pred\n"
     ]
    }
   ],
   "source": [
    "Xy_test['Prediction'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1588</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1591</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1592</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>398 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label  Prediction\n",
       "1588      1           1\n",
       "1589      0           1\n",
       "1590      1           0\n",
       "1591      0           1\n",
       "1592      0           0\n",
       "...     ...         ...\n",
       "1981      0           0\n",
       "1982      1           0\n",
       "1983      1           1\n",
       "1984      1           1\n",
       "1985      1           1\n",
       "\n",
       "[398 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xy_test[['Label', 'Prediction']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = len(Xy_test[(Xy_test['Label']==1) & (Xy_test['Prediction']==1)])\n",
    "fp = len(Xy_test[(Xy_test['Label']==0) & (Xy_test['Prediction']==1)])\n",
    "tn = len(Xy_test[(Xy_test['Label']==0) & (Xy_test['Prediction']==0)])\n",
    "fn = len(Xy_test[(Xy_test['Label']==1) & (Xy_test['Prediction']==0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "f_measure = (2 * precision * recall) / (precision + recall)\n",
    "accuracy = (tp+tn)/(tp+tn+fp+fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4752475247524752\n",
      "0.4752475247524752\n",
      "0.4752475247524752\n",
      "0.46733668341708545\n"
     ]
    }
   ],
   "source": [
    "print(precision)\n",
    "print(recall)\n",
    "print(f_measure)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
